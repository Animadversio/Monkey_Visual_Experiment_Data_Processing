{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp Record Editting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel(r\"D:\\ExpRecord_tmp.xlsx\")\n",
    "df_formal = pd.read_excel(r\"S:\\ExpSpecTable_Augment.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_concat_cells(df, out_excel, Animal):\n",
    "    \"\"\"Process the raw form excel copied from onenote to well formed excel\n",
    "    Filter the array using `Animal` label\"\"\n",
    "    \"\"\"\n",
    "    if isinstance(df,str):\n",
    "        df = pd.read_excel(df)\n",
    "    df = df.dropna(axis=0, how='all') # drop lines full with nan\n",
    "    df = df.reset_index(drop=True)  # (index=range(df.shape[0]))  # make the index contiguous!\n",
    "    row_num = df.shape[0]\n",
    "    #%%\n",
    "    msk = ~ df.ephysFN.isna()  # 500 rows\n",
    "    # df.ephysFN[msk].str.contains(\"Alfa\")  # 436 rows containing Alfa\n",
    "    if Animal is \"Alfa\":\n",
    "        search_str = \"Alfa|ALfa\"\n",
    "    elif Animal is \"Beto\":\n",
    "        search_str = \"Beto\"\n",
    "    elif Animal is \"Both\":\n",
    "        search_str = \"Beto|Alfa|ALfa\"\n",
    "    else:\n",
    "        search_str = \"Beto|Alfa|ALfa\"\n",
    "    ExpEphysNames = df.ephysFN[df.ephysFN.str.contains(search_str)==True]\n",
    "    RowidEphs = ExpEphysNames.index\n",
    "    ExpBhv2Names = df.expControlFN[df.expControlFN.str.contains(search_str)==True]\n",
    "    RowidBhv = ExpEphysNames.index\n",
    "    assert RowidEphs is RowidBhv\n",
    "    #%%\n",
    "    df.comments.fillna(value=\"\", inplace=True)\n",
    "    df.comments = df.comments.astype(\"str\")\n",
    "    df.stimuli.fillna(value=\"\", inplace=True)\n",
    "    df.stimuli = df.stimuli.astype(\"str\")\n",
    "    #%%\n",
    "    for Expi, rowi in enumerate(RowidEphs):\n",
    "        if Expi != len(RowidEphs) - 1:\n",
    "            nextrow = RowidEphs[Expi + 1]\n",
    "        else:\n",
    "            nextrow = row_num\n",
    "        print(\"\\nExp %d\\t %s\\t %s\"%( Expi, df.ephysFN[rowi], df.expControlFN[rowi]))\n",
    "        print(df.comments[rowi:nextrow].str.cat(sep=\"\\n\"))\n",
    "    # \n",
    "    stimuli_miss_cnt = 0  # Count how many stimuli entries are missed\n",
    "    df_sort = df[df.ephysFN.str.contains(search_str)==True]\n",
    "    df_sort = df_sort.reset_index(drop=True)\n",
    "    for Expi, rowi in enumerate(RowidEphs):\n",
    "        if Expi != len(RowidEphs) - 1:\n",
    "            nextrow = RowidEphs[Expi + 1]\n",
    "        else:\n",
    "            nextrow = row_num\n",
    "        df_sort.comments[Expi] = df.comments[rowi:nextrow].str.cat(sep=\"\\n\")\n",
    "        df_sort.ephysFN[Expi] = df.ephysFN[rowi]\n",
    "        df_sort.expControlFN[Expi] = df.expControlFN[rowi]\n",
    "        if \"Stimuli\" in df.stimuli[rowi]:\n",
    "            df_sort.stimuli[Expi] = df.stimuli[rowi]\n",
    "        else:\n",
    "            df_sort.stimuli[Expi] = \"\"\n",
    "            stimuli_miss_cnt += 1\n",
    "            # print out info for further examination\n",
    "            print(\"\\nExp %d\\t %s\\t %s\" % (Expi, df.ephysFN[rowi], df.expControlFN[rowi]))\n",
    "            print(df.stimuli[rowi:nextrow].str.cat(sep=\"\"))\n",
    "            if (\"Abort\" in df_sort.comments[Expi]) or (\"abort\" in df_sort.comments[Expi]):\n",
    "                print(\"Do aborted! No worry.\")\n",
    "    print(stimuli_miss_cnt, \"stimuli missing\")\n",
    "    #%%\n",
    "    df_sort.to_excel(out_excel,index=False)\n",
    "    return df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_formal.expControlFN==name).nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_table(df_old, df_new, addexplabel=None, out_path=None):\n",
    "    if isinstance(df_old,str):\n",
    "        out_path = df_old\n",
    "        df_old = pd.read_excel(df_old)\n",
    "    if isinstance(df_new,str):\n",
    "        df_new = pd.read_excel(df_new)\n",
    "    # Check if the experiments in the new datatable has been recorded\n",
    "    break_flag = False\n",
    "    for name in df_new.expControlFN:\n",
    "        if (df_old.expControlFN==name).any():\n",
    "            print(\"%s  has been recorded in the excel index %d, please check\"%(name, (df_old.expControlFN==name).nonzero()[0][0]))\n",
    "            break_flag = True\n",
    "    if break_flag:\n",
    "        raise ValueError\n",
    "    if addexplabel is not None:\n",
    "        df_new.Exp_collection[:] = addexplabel\n",
    "    df_cat = pd.concat([df_old,df_new], axis=0, ignore_index=True)\n",
    "    df_cat.to_excel(out_path,index=False)\n",
    "    return df_cat\n",
    "\n",
    "def sort_merge_table(df_sort, addexplabel=None):\n",
    "    Animal_strs = [\"Alfa\", \"Beto\"]\n",
    "    df_paths = [r\"S:\\Exp_Record_Alfa.xlsx\", r\"S:\\ExpSpecTable_Augment.xlsx\"]\n",
    "    if isinstance(df_sort,str):\n",
    "        df_sort = pd.read_excel(df_sort)\n",
    "    # loop through animal name and sort corresponding exp to the collection\n",
    "    for animal, out_path in zip(Animal_strs, df_paths):\n",
    "        print(\"Sort out exp for %s, adding \"%animal)\n",
    "        df_old = pd.read_excel(out_path) # load the old exp collection\n",
    "        id_col = []\n",
    "        for idx in df_sort.index:\n",
    "            name = df_sort.expControlFN[idx]\n",
    "            if animal in name:\n",
    "                if (df_old.expControlFN==name).any():\n",
    "                    print(\"%s  has been recorded in the excel index %d, please check. Skipping.\"%(name, (df_old.expControlFN==name).nonzero()[0][0]))\n",
    "                else:\n",
    "                    id_col.append(idx)\n",
    "        df_ftr = df_sort.iloc[id_col].copy()\n",
    "        print(df_ftr.expControlFN)\n",
    "        if addexplabel is not None:\n",
    "            df_ftr.Exp_collection[:] = addexplabel\n",
    "        df_cat = pd.concat([df_old, df_ftr], axis=0, ignore_index=True)\n",
    "        df_cat.to_excel(out_path,index=False) # write to the excel of all old experiments \n",
    "    return\n",
    "# pd.concat([df_formal,df_sort], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             200318_Beto_rfMapper_basic\n",
       "1          200318_Beto_rfMapper_basic(1)\n",
       "2          200318_Beto_rfMapper_basic(2)\n",
       "3     200318_Beto_generate_integrated(1)\n",
       "4     200318_Beto_generate_integrated(2)\n",
       "5     200318_Beto_generate_integrated(3)\n",
       "6     200318_Beto_generate_integrated(4)\n",
       "7     200318_Beto_generate_integrated(5)\n",
       "8             200318_Alfa_rfMapper_basic\n",
       "9          200318_Alfa_rfMapper_basic(1)\n",
       "10       200318_Alfa_generate_integrated\n",
       "11    200318_Alfa_generate_integrated(1)\n",
       "12    200318_Alfa_generate_integrated(2)\n",
       "13    200318_Alfa_generate_integrated(3)\n",
       "14    200318_Alfa_generate_integrated(4)\n",
       "Name: expControlFN, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sort.expControlFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200318_Beto_rfMapper_basic(1)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sort.expControlFN[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exp 0\t Beto-18032020-001\t 200318_Beto_rfMapper_basic\n",
      "001 RFMapping 11:\n",
      "-8:8:8 \n",
      "Carlos' huge image test\n",
      "Completed\n",
      "\n",
      "Exp 1\t Beto-18032020-002\t 200318_Beto_rfMapper_basic(1)\n",
      "002 RFMapping starts 11:35\n",
      "-8:2:8\n",
      "Completed\n",
      "\n",
      "Exp 2\t Beto-18032020-003\t 200318_Beto_rfMapper_basic(2)\n",
      "003 RFMapping starts 11:49\n",
      "-4:1:4\n",
      "8 mins similar RF position\n",
      "Completed\n",
      "\n",
      "Exp 3\t Beto-18032020-004\t 200318_Beto_generate_integrated(1)\n",
      "004 Generate Integrated\n",
      "24 [-1.5 1.5 ] 4 1 CMAES\n",
      "Trying out basic optimizer, see if it can evolve!\n",
      "Seems work, Evolving very fast.\n",
      "Seems plateau really fast as well around 10 gens. Only 6 mins! Wow. Maybe 20 blocks\n",
      "Why Stuck so early? Gets some local maxima? \n",
      "Completed\n",
      "\n",
      "Exp 4\t Beto-18032020-005\t 200318_Beto_generate_integrated(2)\n",
      "005 Generate Integrated\n",
      "24 [-1.5 1.5 ] 4 1 ZOHA_Sphere_lr_euclid\n",
      "24 [-1.5 1.5 ] 4 1 ZOHA_Sphere_lr_euclid_RD\n",
      "Test the reduced Dimension Comparison.\n",
      "Use the inverse decay exploration range. lr=1.5\n",
      "Inverse decay's initial learning rate is too large, should make it smaller. And learning rate * exploration exceeds pi/2 it's insane.\n",
      "(Gen 5 explor is 58.3 deg, step is 0.88 or 0.64)\n",
      "Gen 12 42 degs, step 0.474, 0.314, this is good.\n",
      "Gap exist! But quite small. (only 14 mins now! )\n",
      "Plateau around 15 gens\n",
      "Completed\n",
      "\n",
      "Exp 5\t Beto-18032020-006\t 200318_Beto_generate_integrated(3)\n",
      "006 Generate Integrated\n",
      "24 [-1.5 1.5 ] 4 1 ZOHA_Sphere_lr_euclid\n",
      "24 [-1.5 1.5 ] 4 1 ZOHA_Sphere_lr_euclid_RD\n",
      "Redo the reduced Dimension Comparison.\n",
      "Use the inverse decay exploration range. Lr=1.2 Decrease this to avoid overshoot. And this makes Sphere lr euclid grow just as fast as CMAES! No delay!\n",
      "gen 11, 45 deg 0.321.\n",
      "Interestingly, the reduced starts to grow at around gen 12. Making gap smaller.\n",
      "Finished in 30 mins\n",
      "Completed\n",
      "\n",
      "Exp 6\t Beto-18032020-007\t 200318_Beto_generate_integrated(4)\n",
      "007 Generate Integrated starts 13:30\n",
      "64 [-1.5 -2.5 ] 5 1 ZOHA_Sphere_lr_euclid\n",
      "64 [-1.5 -2.5 ] 5 1 ZOHA_Sphere_lr_euclid_RD\n",
      "Test the Reduced Dimension for V4 channel on Beto.\n",
      "ZOHA full saturates pretty fast!\n",
      "Seems there is still a gap and it's not small……\n",
      "Wow, gap gets closed…… as expected.\n",
      "Really the same as expected! It closes the gap finally.\n",
      "takes 35 min to get to 25 blocks! Good job.\n",
      "Completed\n",
      "\n",
      "Exp 7\t Beto-18032020-008\t 200318_Beto_generate_integrated(5)\n",
      "008 Generate Integrated starts 14:10\n",
      "64 [-1.5 -2.5 ] 5 1 ZOHA_Sphere_lr_euclid_RD\n",
      "64 [-1.5 -2.5 ] 5 1 ZOHA_Sphere_lr_euclid_RD\n",
      "Test the Reduced Dimension for V4 channel on Beto.\n",
      "See how large is the trial variability.\n",
      "The first one saturates pretty fast as well.\n",
      "the first one gets even higher than full, seemingly! OMG.\n",
      "At gen 10 the step size is around 0.376!\n",
      "Oh get back to normal… seems higher than Full evolution is just fluctuation.\n",
      "Gen 13 exploration aaround 41.8.\n",
      "Around 18 gens the 1st evolution grows again! Find something new to add to the image.\n",
      "Gets to ~ 30 gens……\n",
      "Add 100mL water to him!\n",
      "Completed\n",
      "\n",
      "Exp 8\t Alfa64chan-18032020-001\t 200318_Alfa_rfMapper_basic\n",
      "001 Rf mapper 8, [8 8] start at 1:06\n",
      "10 blocks complete, stop at 1:08\n",
      "\n",
      "Exp 9\t Alfa64chan-18032020-002\t 200318_Alfa_rfMapper_basic(1)\n",
      "002 Rf mapper\n",
      "002 2 [8 8] start at 1:10\n",
      "Ch 1, very sparse, tiny rf field\n",
      "Ch 24, looks pretty good\n",
      "5 blocks comple, stop at 1:14\n",
      "\n",
      "Exp 10\t Alfa64chan-18032020-003\t 200318_Alfa_generate_integrated\n",
      "003 Generate integrated ch 30, hash, start at 1:22\n",
      "30 [0, -1.5] 3 1 'ZOHA_Sphere_lr euclid'\n",
      "30 [0, -1.5]  3 1 'ZOHA_Sphere_lr euclid_ReducDim'\n",
      "25 blocks complete, stop at 145\n",
      "\n",
      "Exp 11\t Alfa64chan-18032020-004\t 200318_Alfa_generate_integrated(1)\n",
      "004 Same thing over again, start 1:46\n",
      "30 [0, -1.5] 3 1 'ZOHA_Sphere_lr euclid'\n",
      "30 [0, -1.5]  3 1 'ZOHA_Sphere_lr euclid_ReducDim'\n",
      "Stop after 27 blocks, 2:10\n",
      "\n",
      "Exp 12\t Alfa64chan-18032020-005\t 200318_Alfa_generate_integrated(2)\n",
      "005 Generate integrated ch 58, whole hash\n",
      "58 [-0.7, -2] 4 1 'ZOHA_Sphere_lr euclid'\n",
      "58 [-0.7, -2]  4 1 'ZOHA_Sphere_lr euclid_ReducDim'\n",
      "We are doing the whole channel this time, but may be able to separate a SU out, try that next\n",
      "Stayed above natural images but never took off\n",
      "Going to block 20, then grab SU and try again\n",
      "19 blocks complete stop at 232\n",
      "\n",
      "Exp 13\t Alfa64chan-18032020-006\t 200318_Alfa_generate_integrated(3)\n",
      "006 generate integrated ch 58, SU\n",
      "58 [-0.7, -2] 4 1 'ZOHA_Sphere_lr euclid'\n",
      "58 [-0.7, -2]  4 1 'ZOHA_Sphere_lr euclid_ReducDim'\n",
      "Looking good, climbing already at block 3\n",
      "Block 14, still slowly climbing.\n",
      "complete\n",
      "\n",
      "Exp 14\t Alfa64chan-18032020-007\t 200318_Alfa_generate_integrated(4)\n",
      "007 generate integrated, ch 34 hash\n",
      "34 [0 0 ] 3 1 'ZOHA_Sphere_lr euclid'\n",
      "34  [0 0]  3 1 'ZOHA_Sphere_lr euclid_ReducDim'\n",
      "Reward at 200 plus 35 aq reward\n",
      "Will take forever…… finish him….\n",
      "8 blocks in 26 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 stimuli missing\n"
     ]
    }
   ],
   "source": [
    "Animal = \"Both\"#\"Beto\" # \"Alfa\" \"ALfa\"\n",
    "df_sort = process_concat_cells(r\"D:\\ExpRecord_tmp.xlsx\", \"D:\\ExpRecord_out.xlsx\", animal=Animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ephysFN</th>\n",
       "      <th>expControlFN</th>\n",
       "      <th>stimuli</th>\n",
       "      <th>comments</th>\n",
       "      <th>Exp_collection</th>\n",
       "      <th>Expi</th>\n",
       "      <th>pref_chan</th>\n",
       "      <th>stim_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beto-18032020-001</td>\n",
       "      <td>200318_Beto_rfMapper_basic</td>\n",
       "      <td>N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Beto</td>\n",
       "      <td>001 RFMapping 11:\\n-8:8:8 \\nCarlos' huge image...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beto-18032020-002</td>\n",
       "      <td>200318_Beto_rfMapper_basic(1)</td>\n",
       "      <td>N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Beto</td>\n",
       "      <td>002 RFMapping starts 11:35\\n-8:2:8\\nCompleted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beto-18032020-003</td>\n",
       "      <td>200318_Beto_rfMapper_basic(2)</td>\n",
       "      <td>N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Beto</td>\n",
       "      <td>003 RFMapping starts 11:49\\n-4:1:4\\n8 mins sim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beto-18032020-004</td>\n",
       "      <td>200318_Beto_generate_integrated(1)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...</td>\n",
       "      <td>004 Generate Integrated\\n24 [-1.5 1.5 ] 4 1 CM...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beto-18032020-005</td>\n",
       "      <td>200318_Beto_generate_integrated(2)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...</td>\n",
       "      <td>005 Generate Integrated\\n24 [-1.5 1.5 ] 4 1 ZO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beto-18032020-006</td>\n",
       "      <td>200318_Beto_generate_integrated(3)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...</td>\n",
       "      <td>006 Generate Integrated\\n24 [-1.5 1.5 ] 4 1 ZO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Beto-18032020-007</td>\n",
       "      <td>200318_Beto_generate_integrated(4)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...</td>\n",
       "      <td>007 Generate Integrated starts 13:30\\n64 [-1.5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beto-18032020-008</td>\n",
       "      <td>200318_Beto_generate_integrated(5)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...</td>\n",
       "      <td>008 Generate Integrated starts 14:10\\n64 [-1.5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alfa64chan-18032020-001</td>\n",
       "      <td>200318_Alfa_rfMapper_basic</td>\n",
       "      <td>N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Alfa</td>\n",
       "      <td>001 Rf mapper 8, [8 8] start at 1:06\\n10 block...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alfa64chan-18032020-002</td>\n",
       "      <td>200318_Alfa_rfMapper_basic(1)</td>\n",
       "      <td>N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Alfa</td>\n",
       "      <td>002 Rf mapper\\n002 2 [8 8] start at 1:10\\nCh 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alfa64chan-18032020-003</td>\n",
       "      <td>200318_Alfa_generate_integrated</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...</td>\n",
       "      <td>003 Generate integrated ch 30, hash, start at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alfa64chan-18032020-004</td>\n",
       "      <td>200318_Alfa_generate_integrated(1)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...</td>\n",
       "      <td>004 Same thing over again, start 1:46\\n30 [0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alfa64chan-18032020-005</td>\n",
       "      <td>200318_Alfa_generate_integrated(2)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...</td>\n",
       "      <td>005 Generate integrated ch 58, whole hash\\n58 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alfa64chan-18032020-006</td>\n",
       "      <td>200318_Alfa_generate_integrated(3)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...</td>\n",
       "      <td>006 generate integrated ch 58, SU\\n58 [-0.7, -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alfa64chan-18032020-007</td>\n",
       "      <td>200318_Alfa_generate_integrated(4)</td>\n",
       "      <td>N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...</td>\n",
       "      <td>007 generate integrated, ch 34 hash\\n34 [0 0 ]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ephysFN                        expControlFN  \\\n",
       "0         Beto-18032020-001          200318_Beto_rfMapper_basic   \n",
       "1         Beto-18032020-002       200318_Beto_rfMapper_basic(1)   \n",
       "2         Beto-18032020-003       200318_Beto_rfMapper_basic(2)   \n",
       "3         Beto-18032020-004  200318_Beto_generate_integrated(1)   \n",
       "4         Beto-18032020-005  200318_Beto_generate_integrated(2)   \n",
       "5         Beto-18032020-006  200318_Beto_generate_integrated(3)   \n",
       "6         Beto-18032020-007  200318_Beto_generate_integrated(4)   \n",
       "7         Beto-18032020-008  200318_Beto_generate_integrated(5)   \n",
       "8   Alfa64chan-18032020-001          200318_Alfa_rfMapper_basic   \n",
       "9   Alfa64chan-18032020-002       200318_Alfa_rfMapper_basic(1)   \n",
       "10  Alfa64chan-18032020-003     200318_Alfa_generate_integrated   \n",
       "11  Alfa64chan-18032020-004  200318_Alfa_generate_integrated(1)   \n",
       "12  Alfa64chan-18032020-005  200318_Alfa_generate_integrated(2)   \n",
       "13  Alfa64chan-18032020-006  200318_Alfa_generate_integrated(3)   \n",
       "14  Alfa64chan-18032020-007  200318_Alfa_generate_integrated(4)   \n",
       "\n",
       "                                              stimuli  \\\n",
       "0       N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Beto   \n",
       "1       N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Beto   \n",
       "2       N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Beto   \n",
       "3   N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...   \n",
       "4   N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...   \n",
       "5   N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...   \n",
       "6   N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...   \n",
       "7   N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Beto-...   \n",
       "8       N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Alfa   \n",
       "9       N:\\Stimuli\\2019-06-RF-mapping\\2020-03-18-Alfa   \n",
       "10  N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...   \n",
       "11  N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...   \n",
       "12  N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...   \n",
       "13  N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...   \n",
       "14  N:\\Stimuli\\2019-12-Evolutions\\2020-03-18-Alfa-...   \n",
       "\n",
       "                                             comments  Exp_collection  Expi  \\\n",
       "0   001 RFMapping 11:\\n-8:8:8 \\nCarlos' huge image...             NaN   NaN   \n",
       "1       002 RFMapping starts 11:35\\n-8:2:8\\nCompleted             NaN   NaN   \n",
       "2   003 RFMapping starts 11:49\\n-4:1:4\\n8 mins sim...             NaN   NaN   \n",
       "3   004 Generate Integrated\\n24 [-1.5 1.5 ] 4 1 CM...             NaN   NaN   \n",
       "4   005 Generate Integrated\\n24 [-1.5 1.5 ] 4 1 ZO...             NaN   NaN   \n",
       "5   006 Generate Integrated\\n24 [-1.5 1.5 ] 4 1 ZO...             NaN   NaN   \n",
       "6   007 Generate Integrated starts 13:30\\n64 [-1.5...             NaN   NaN   \n",
       "7   008 Generate Integrated starts 14:10\\n64 [-1.5...             NaN   NaN   \n",
       "8   001 Rf mapper 8, [8 8] start at 1:06\\n10 block...             NaN   NaN   \n",
       "9   002 Rf mapper\\n002 2 [8 8] start at 1:10\\nCh 1...             NaN   NaN   \n",
       "10  003 Generate integrated ch 30, hash, start at ...             NaN   NaN   \n",
       "11  004 Same thing over again, start 1:46\\n30 [0, ...             NaN   NaN   \n",
       "12  005 Generate integrated ch 58, whole hash\\n58 ...             NaN   NaN   \n",
       "13  006 generate integrated ch 58, SU\\n58 [-0.7, -...             NaN   NaN   \n",
       "14  007 generate integrated, ch 34 hash\\n34 [0 0 ]...             NaN   NaN   \n",
       "\n",
       "    pref_chan  stim_size  \n",
       "0         NaN        NaN  \n",
       "1         NaN        NaN  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  \n",
       "5         NaN        NaN  \n",
       "6         NaN        NaN  \n",
       "7         NaN        NaN  \n",
       "8         NaN        NaN  \n",
       "9         NaN        NaN  \n",
       "10        NaN        NaN  \n",
       "11        NaN        NaN  \n",
       "12        NaN        NaN  \n",
       "13        NaN        NaN  \n",
       "14        NaN        NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort out exp for Alfa, adding \n",
      "8             200318_Alfa_rfMapper_basic\n",
      "9          200318_Alfa_rfMapper_basic(1)\n",
      "10       200318_Alfa_generate_integrated\n",
      "11    200318_Alfa_generate_integrated(1)\n",
      "12    200318_Alfa_generate_integrated(2)\n",
      "13    200318_Alfa_generate_integrated(3)\n",
      "14    200318_Alfa_generate_integrated(4)\n",
      "Name: expControlFN, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort out exp for Beto, adding \n",
      "200318_Beto_rfMapper_basic  has been recorded in the excel index 177, please check. Skipping.\n",
      "200318_Beto_rfMapper_basic(1)  has been recorded in the excel index 178, please check. Skipping.\n",
      "200318_Beto_rfMapper_basic(2)  has been recorded in the excel index 179, please check. Skipping.\n",
      "200318_Beto_generate_integrated(1)  has been recorded in the excel index 180, please check. Skipping.\n",
      "200318_Beto_generate_integrated(2)  has been recorded in the excel index 181, please check. Skipping.\n",
      "200318_Beto_generate_integrated(3)  has been recorded in the excel index 182, please check. Skipping.\n",
      "200318_Beto_generate_integrated(4)  has been recorded in the excel index 183, please check. Skipping.\n",
      "200318_Beto_generate_integrated(5)  has been recorded in the excel index 184, please check. Skipping.\n",
      "Series([], Name: expControlFN, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "sort_merge_table(df_sort, addexplabel=\"ReducDimen_Evol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "if Animal == \"Beto\":\n",
    "    table_old = r\"S:\\ExpSpecTable_Augment.xlsx\"\n",
    "elif Animal == \"Alfa\":\n",
    "    table_old = r\"S:\\Exp_Record_Alfa.xlsx\"\n",
    "df_cat = concat_table(table_old, r\"D:\\ExpRecord_out.xlsx\", addexplabel=\"ReducDimen_Evol\") # \"Optim_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_sort.Exp_collection[:] = \"SUHash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!S:\\ExpSpecTable_Augment.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The process cannot access the file because it is being used by another process.\n"
     ]
    }
   ],
   "source": [
    "!S:\\Exp_Record_Alfa.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matlab Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "format compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already SUBSTed \n",
      "\n",
      "ans =\n",
      "\n",
      "     1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Set_Path;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "winopen(\"S:\\ExpSpecTable_Augment.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "open(\"Project_Manifold_Beto_loadRaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "open(\"Evol_Optimizer_Cmp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
